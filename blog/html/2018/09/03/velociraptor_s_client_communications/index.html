<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.108.0"><meta name=description content="In the latest point release of the Velociraptor IR tool (0.2.3) we
have improved upon GRR's client communications protocol to deliver a
fast and efficient, yet extremely responsive client
communication. This post explains the design of the client
communication and how it solves the problems with the old GRR's client
communication.
"><link rel=icon href=/images/favicon.png type=image/png><title>Velociraptor's client communications :: Velociraptor - Digging deeper!</title><link href=/css/nucleus.css?1671136356 rel=stylesheet><link href=/css/fontawesome-all.min.css?1671136356 rel=stylesheet><link href=/css/featherlight.min.css?1671136356 rel=stylesheet><link href=/css/perfect-scrollbar.min.css?1671136356 rel=stylesheet><link href=/css/auto-complete.css?1671136356 rel=stylesheet><link href=/css/theme.css?1671136356 rel=stylesheet><link href=/css/tabs.css?1671136356 rel=stylesheet><link href=/css/hugo-theme.css?1671136356 rel=stylesheet><link href=/css/theme-mine.css?1671136356 rel=stylesheet><link href=/css/dark.css?1671136356 rel=stylesheet><link href=/css/syntax.css?1671136356 rel=stylesheet><link href=/css/light.css?1671136356 rel=stylesheet><link href=/css/hljs.css?1671136356 rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css?1671136356 rel=stylesheet><script src=/js/jquery-3.3.1.min.js?1671136356></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-QYH72LMYCS"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QYH72LMYCS",{anonymize_ip:!1})}</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-QYH72LMYCS","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script>
<script></script></head><body data-url=/blog/html/2018/09/03/velociraptor_s_client_communications/><nav id=sidebar><div id=header-wrapper><div id=header><script>function darkmode(){$("body").addClass("dark").removeClass("light"),document.cookie="theme=darkmode;path=/"}function lightmode(){$("body").removeClass("dark").addClass("light"),document.cookie="theme=lightmode;path=/"}const regex=new RegExp("theme=darkmode");regex.test(document.cookie)?darkmode():lightmode()</script><div class="btn btn-default ThemeSelector darkmode" onclick=darkmode()><i class="fas fa-moon"></i></div><div class="btn btn-default ThemeSelector lightmode" onclick=lightmode()><i class="fas fa-sun"></i></div><a href=https://docs.velociraptor.app/><img src=https://docs.velociraptor.app//images/logo.svg></a></div></div><div class=highlightable><ul class=topics><li data-nav-id=https://docs.velociraptor.app/docs/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/><i class="fas fa-book-reader"></i>Documentation</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/overview/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/overview/>Velociraptor Overview</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/overview/history/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/overview/history/>History</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/overview/support/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/overview/support/>Support Policy</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/deployment/>Deployment</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/deployment/self-signed/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/self-signed/>Self-Signed SSL</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/cloud/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/deployment/cloud/>Cloud Deployment</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/deployment/cloud/multifrontend/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/cloud/multifrontend/>Multi-Frontend</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/clients/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/clients/>Deploying Clients</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/rbac/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/rbac/>Users and Roles</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/resources/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/resources/>Performance</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/troubleshooting/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/troubleshooting/>Troubleshooting</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/deployment/references/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/deployment/references/>Config Reference</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/gui/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/gui/>The Admin GUI</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/gui/clients/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/gui/clients/>Inspecting clients</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/gui/vfs/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/gui/vfs/>The VFS</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/gui/artifacts/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/gui/artifacts/>Artifacts</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/gui/hunting/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/gui/hunting/>Hunting</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/vql/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/vql/>VQL Fundamentals</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/vql/notebooks/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/vql/notebooks/>Notebooks</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/vql/artifacts/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/vql/artifacts/>Artifacts</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/vql/events/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/vql/events/>Event Queries</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/forensic/>Forensic Analysis</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/forensic/filesystem/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/filesystem/>Searching Filenames</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/searching/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/searching/>Searching Content</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/ntfs/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/ntfs/>NTFS Analysis</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/binary/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/binary/>Binary parsing</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/evidence_of_execution/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/evidence_of_execution/>Evidence Of Execution</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/event_logs/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/event_logs/>Event Logs</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/forensic/volatile/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/forensic/volatile/>Volatile State</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/docs/offline_triage/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/offline_triage/>Triage and acquisition</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/client_monitoring/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/client_monitoring/>Client Monitoring</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/extending_vql/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/extending_vql/>Extending VQL</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/server_automation/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/docs/server_automation/>Server Automation</a></div><ul><li data-nav-id=https://docs.velociraptor.app/docs/server_automation/server_api/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/server_automation/server_api/>Server API</a></div></li><li data-nav-id=https://docs.velociraptor.app/docs/server_automation/server_monitoring/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/docs/server_automation/server_monitoring/>Server Monitoring</a></div></li></ul></li></ul></li><hr><li data-nav-id=https://docs.velociraptor.app/vql_reference/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/vql_reference/><i class="fas fa-book"></i>VQL Reference</a></div><ul><li data-nav-id=https://docs.velociraptor.app/vql_reference/basic/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/basic/>Basic VQL</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/linux/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/linux/>Linux Specific</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/windows/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/windows/>Windows Specific</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/parsers/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/parsers/>Parsers</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/server/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/server/>Server Side</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/plugin/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/plugin/>Client Side</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/event/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/event/>Event Plugins</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/experimental/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/experimental/>Experimental</a></div></li><li data-nav-id=https://docs.velociraptor.app/vql_reference/misc/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/vql_reference/misc/>Misc</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/training/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/training/><i class="fas fa-graduation-cap"></i>Training</a></div></li><li data-nav-id=https://docs.velociraptor.app/blog/ class="dd-item parent haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/blog/><i class="fas fa-newspaper"></i>Blog</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/ class="dd-item haschildren"><div><i class="fa fa-angle-right fa-sm category-icon"></i>
<a href=/presentations/><i class="fas fa-chalkboard-teacher"></i>Presentations</a></div><ul><li data-nav-id=https://docs.velociraptor.app/presentations/2022_linuxconf_au/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_linuxconf_au/>Linux Conf Au 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_auscert/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_auscert/>Auscert 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_dfrws_us/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_dfrws_us/>DFRWS US 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_tech_user_group_cbr/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_tech_user_group_cbr/>Tech Users Group 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_sans_summit/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_sans_summit/>SANS Summit 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_velocon/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_velocon/>Velocon 2022</a></div></li><li data-nav-id=https://docs.velociraptor.app/presentations/2022_dfrws_apac/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/presentations/2022_dfrws_apac/>DFRWS APAC 2022</a></div></li></ul></li><li data-nav-id=https://docs.velociraptor.app/exchange/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/exchange/><i class="fas fa-code"></i>Artifact Exchange</a></div></li><li data-nav-id=https://docs.velociraptor.app/artifact_references/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/artifact_references/><i class="fas fa-book"></i>Artifact Reference</a></div></li><li data-nav-id=https://docs.velociraptor.app/knowledge_base/ class="dd-item haschildren"><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/knowledge_base/><i class="fas fa-brain"></i>Knowledge Base</a></div></li><li data-nav-id=https://docs.velociraptor.app/search/ class=dd-item><div><i class="fa fa-circleXX fa-sm category-icon"></i>
<a href=/search/><i class='fas fa-search'></i>Search</a></div></li></ul><hr><section id=shortcuts><h3></h3><ul><li><a class=padding href=https://github.com/Velocidex/velociraptor><i class='fab fa-github'></i>Github</a></li><li><a class=padding href=https://docs.velociraptor.app/discord/><i class='fab fa-discord'></i>Discord</a></li><li><a class=padding href=mailto:velociraptor-discuss@googlegroups.com><i class='fas fa-envelope'></i>Mailing List</a></li><li><a class=padding href=https://docs.velociraptor.app/rss/><i class='fas fa-rss'></i>RSS</a></li></ul></section><section id=footer><div class=footer-copyright>Brought to you by
<img src=/images/Rapid7_logo.svg class=rapid7><br><i class="fas fa-copyright"></i> 2022</div></section></div></nav><script>$("#sidebar i.fa-angle-right").each(function(){$(this).parent().parent().find("ul").hide()})</script><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=top-github-link><a class=github-link title='Edit this page' href=https://github.com/Velocidex/velociraptor-docs/edit/master/content/blog/html/2018/09/03/velociraptor_s_client_communications/_index.md target=blank><i class="fas fa-code-branch"></i>
<span id=top-github-link-text>Edit this page</span></a></div><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i></a></span>
<span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links>Velociraptor's client communications</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><ul><li><a href=#how-does-the-grr-client-communicate>How does the GRR client communicate?</a></li></ul></li></ul><ul><li><a href=#making-the-client-more-responsive>Making the client more responsive</a></li><li><a href=#conclusions>Conclusions</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Velociraptor's client communications</h1><h3 id=how-does-the-grr-client-communicate>How does the GRR client communicate?</h3><p>The GRR client protocol is depicted below.</p><p><img src=comms1.png alt></p><p>Due to network realities such as NAT, firewalls etc, it is not possible
to directly connect to the client, so GRR relies on the client
connecting to the server in order to communicate with it.</p><p>The GRR client makes periodic POST requests to the server to both send
replies and receive new instructions. Since POST requests are very short
lived (most client polls carry no data) the client has to repeat the
polls periodically.</p><p>There are two parameters which determine how the GRR client behaves
-poll_max and poll_min. When there is some requests sent to the
client, the client will reduce its poll wait time to poll_min (default
0.2 seconds). When nothing happens, the client will increase its poll
time gradually up to poll_max (default 10 minutes).</p><p>Having long poll times means that any new flows launched on an idle
client must wait for up to 10 minutes before the client polls again in
order to send the new requests to the client. Unfortunately reducing the
poll_max setting actually increases server load, as the server needs to
hit the database more often to serve each poll. This scheme essentially
poses a trade off - for a responsive client, we must have a low
poll_max (i.e. more frequent polls) but this increases the load on the
frontend so it can not be too low.</p><p>When GRR is normally deployed it produces 2 types of clients on the web
interface: the debug client has max_poll set to 5 seconds making
testing easier because it is more responsive, but the non-debug version
has max_poll set to 10 minutes. For example at Velocidex, one of our
clients had once accidentally deployed the debug version and the server
was slammed with 5 second polls from several thousand clients! This
rendered the server useless, returning HTTP 500 status codes for most
client polls. The only way to recover was to push new config to the
clients and restart their GRR service in order to lower the poll
frequency and recover control over the deployment.</p><h1 id=catastrophic-failure-under-load>Catastrophic failure under load</h1><p>The other problem with GRR's client communication protocol is that it
tends to exhibit catastrophic failure under load. When the client makes
a HTTP POST operation, the server goes through the following steps in
order:</p><ol><li>Unpack and decrypts any replies the client sends in its POST message</li><li>Queue these replies on a worker queue</li><li>Read the client's job queue for any outstanding requests to the
client.</li><li>Pack and encrypt these requests to the client.</li><li>Write them as the body response of the HTTP POST with hopefully a
200 HTTP status.</li></ol><p>In previous posts we have seen that GRR's overuse of queuing leads to
extreme loads on the database, so under load (e.g. when a large hunt is
taking place), the above process may take some time until the server can
obtain a lock on the database row, write and read the messages, and
compose its response.</p><p>What tends to happen under load, is that the client will time the
request out if the server takes too long, or the server itself may
timeout the request with a HTTP 500 code. The client, thinking it has
not got through will try to POST the same data again (this time it will
wait longer though).</p><p>This essentially makes things worse, because the replies are probably
already mostly queued so the next retry will re-queue the same requests
(these will be discarded by the worker anyway but they are still
queued), increasing database pressure and server load. This manifests in
a critical meltdown of the frontends who pretty soon serve mostly 500
errors (making things worse again).</p><p>This is the reason why resource provision is so important with GRR, if
the frontends are just too slow to be able to keep up, the connections
will start to timeout, and load increases (rather than decreases)
causing a catastrophic failure.</p><h1 id=how-can-we-fix-this>How can we fix this?</h1><p>The main problem with a polling scheme is that the user experience is
terrible - even if we reduce the poll wait times to few seconds, users
will have to wait to view the results of their actions - leading to an
overall experience of a slow and sluggish system. For a responsive user
interface we need to have client round trips of a second or less and
having poll_max set this low will just use up too many resources. This
is particularly noticeable in the VFS browser since it takes so long to
navigate to the desired directory and download files interactively.</p><p>Other endpoint monitoring systems use distributed pub/sub systems like
RabbitMQ or Firebase realtime database to inform the clients of new
requests. In those systems, the client makes a TCP connection to an
endpoint and holds the connection open for long periods of time, the
server can then immediately push new requests to the client as soon as
they are published. This seems like the way to go but we did not want to
introduce another dependency on Velociraptor (we really like it being a
self contained - working out of the box binary).</p><p>In particular we also wanted to solve the catastrophic failure we saw
with GRR clients under load (described above). This means that we need
to make sure that the clients are not sending data faster than the
server can process it. We definitely want to avoid the POST timing out
with a 500 error and the client retrying the same POST since this is the
main cause for the catastrophic failures we experienced with GRR.</p><p>We can do this by keeping the client's connection open for as long as
we need, but in order to not time it out, we send the HTTP status code
immediately, then process the POST data, while sending the client
keepalive data periodically using HTTP chunked transfer encoding.</p><p>To the client, and any proxies in the way, it simply looks like the POST
request was received immediately, and the response body is downloaded
slowly (there is always some pad data flowing so none of the TCP or HTTP
timers are triggered since the connection is always active). This is
illustrated in the diagram below.</p><p><img src=comms2.png alt></p><p>This scheme has the two main advantages:</p><ol><li>By returning a 200 status to the client before we begin processing,
the client knows we received the data. They are then able to
de-queue these messages and will not transmit them again.</li><li>By keeping the client connected while the server is processing the
request we avoid any additional data from being sent to the server
while it is busy. The client will be blocked on the HTTP connection
and will actually pause its running VQL query while the server is
processing the current responses. This mechanism actually throttles
the clients to allow the server to keep up.</li></ol><h2 id=making-the-client-more-responsive>Making the client more responsive</h2><p>We really wanted to make clients more responsive. We were frankly sick
of having to wait up to 10 minutes to access a client that we knew was
online in our IR work. To make the client more responsive we wanted to
use the same technique to keep the client connection open for long
periods of time, and then send instructions to the client as soon as the
user issues a new flow.</p><p>In the GRR scheme new requests are sent on the same connections as
client replies are received. This won't work if the client connection
is held open for long periods of time because while the client is
blocked reading new responses from the server, it can not send any
replies (the POST header was already sent).</p><p>To fix this we switched to two separate POST connections on two server
handlers, a reader handler and a writer handler. The writer handler only
receives messages from the client to the server (i.e. replies to client
requests), while the reader handler blocks the client for prolonged time
and sends client requests as soon as new flows are launched.</p><p>This scheme allows a full duplex, responsive communication protocol,
with no polling overheads. This can be seen in the diagram below.</p><p><img src=comms3.png alt></p><p>The client establishes the reader channel by sending a HTTP POST request
to the reader handler. The server checks for any messages for the
client, and sees that there are none pending. It will then keep the
client's connection open as before, trickle sending pad data (using
HTTP chunked transfer encoding) to keep the connection open for as long
as possible.</p><p>When the user launches a new flow, the server can immediately forward
the client's requests on the open channel, completing the POST
operation. The client will then process the requests and send the
responses with a separate HTTP POST to the writer channel. In the
meantime the reader channel will re-POST to the reader handler and
become blocked and ready for the next request.</p><p>This scheme has the following advantages:</p><ol><li>The user's flow is executed instantly by the client. This makes for
example, the VFS browser instant - as soon as the user clicks the
"refresh directory listing" button, the directory is refreshed. As
soon as the user wants to view a file, the file is downloaded etc.</li><li>There is hardly any polling activity. The clients open a reader
connection once and hold it for many minutes. The server need only
check the queue at the beginning of the connection and then only if
it knows there is a new flow launched for this client. This means
server load is really low.</li></ol><p>However, the scheme also has some disadvantages:</p><ol><li>TCP connections are held for long periods of time tying up server
resources. In particular the open sockets count towards the
process's open file descriptor limit. It is typically necessary to
increase this limit (by default it is 1024 which is very low).</li><li>Deploying over multiple servers is a bit more complex because a
client may be blocked on one server and the flow is launched on
another server. Velociraptor now has a notification API to allow
inter server RPCs to propagate notifications between servers.</li></ol><p>We believe that these limitations can be easily managed. They are no
different from typical limitations of large scale pub/sub systems (they
too need to hold many TCP connections open). In our testing we have not
seen a problem scaling to many thousands of connected clients with very
low resource use.</p><p>Velociraptor now also has a pool client that allows spinning up several
thousand clients at the same time. This helps with testing a deployment
to make sure it can handle the increased open file limit and test how
large scale hunts can be handled.</p><h2 id=conclusions>Conclusions</h2><p>The new responsive client communications protocol allows for near
instantaneous access to clients. This actually reduces the overall load
on the system because we do not need to perform frequent client polls
just to check if a new flow is launched. User experience is much better
as users can interact with clients immediately.</p><footer class=footline></footer></div><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//velocidex-velociraptor.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div id=navigation></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=/js/clipboard.min.js?1671136356></script>
<script src=/js/perfect-scrollbar.min.js?1671136356></script>
<script src=/js/perfect-scrollbar.jquery.min.js?1671136356></script>
<script src=/js/jquery.sticky.js?1671136356></script>
<script src=/js/featherlight.min.js?1671136356></script>
<script src=/js/highlight.min.js?1671136356></script>
<script>hljs.highlightAll()</script><script src=/js/modernizr.custom-3.6.0.js?1671136356></script>
<script src=/js/learn.js?1671136356></script>
<script src=/js/hugo-learn.js?1671136356></script></body></html>